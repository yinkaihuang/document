# kafka 生产者

> 架构图
>
> 核心参数配置讲解
>
> 简单demo
>
> 自定义序列化器
>
> 自定义分区选择器

## 架构图

![](G:\document\resource\prduce2.png)



![](G:\document\resource\produce.png)



## 核心参数讲解

```
bootstrap.servers:用于建立与kafka集群连接的host/port组

acks: producer需要server接收到数据之后发出的确认接收的信号，此项配置就是指procuder需要多少个这样的确认信号
（1）acks=0： 设置为0表示producer不需要等待任何确认收到的信息。
（2）acks=1： 这意味着至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入.<默认参数>
（3）acks=all/-1： 这意味着等待isr中所有副本确认。min.insync.replicas这个参数设定ISR中的最小副本数是多少，默认值为1，当且仅当acks参数设置为-1时，此参数才生效。

buffer.memory：Producer可以用来缓存数据的内存大小。该值实际为RecordAccumulator类中的BufferPool，即Producer所管理的最大内存。如果数据产生速度大于向broker发送的速度，producer会阻塞max.block.ms，超时则抛出异常

linger.ms：producer会将request传输之间到达的所有records聚合到一个批请求。通常这个值发生在欠负载情况下，record到达速度快于发送。但是在某些场景下，client即使在正常负载下也期望减少请求数量。这个设置就是如此，通过人工添加少量时延，而不是立马发送一个record，producer会等待所给的时延，以让其他records发送出去，这样就会被聚合在一起。这个类似于TCP的Nagle算法。该设置给了batch的时延上限：当我们获得一个partition的batch.size大小的records，就会立即发送出去，而不管该设置；但是如果对于这个partition没有累积到足够的record，会linger指定的时间等待更多的records出现。该设置的默认值为0(无时延)。例如，设置linger.ms=5，会减少request发送的数量，但是在无负载下会增加5m

batch.size：Producer可以将发往同一个Partition的数据做成一个Produce Request发送请求，即Batch批处理，以减少请求次数，该值即为每次批处理的大小。另外每个Request请求包含多个Batch，每个Batch对应一个Partition，且一个Request发送的目的Broker均为这些partition的leader副本。若将该值设为0，则不会进行批处理。

retries：生产者从服务器收到的错误消息有可能是临时的，当生产者收到服务器发来的错误消息，会启动重试机制，当充实了n（设置的值）次，还是收到错误消息，那么将会返回错误。生产者会在每次重试之间间隔100ms，不过可以通过retry.backoff.ms改变这个间隔。

max.block.ms：该参数指定了在调用send()方法或使用partitionFor() 方法获取元数据时生产者的阻塞
时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻
塞时间达到max.block.ms 时，生产者会抛出超时异常。

max.request.size：控制生产者发送消息的大小，它可以指定单个消息的最大值，也可以指定单个请求里所有消息大小的总和。比如1MB，那么单个消息最大大小是1MB，同时如果消息大小是1KB，那么一次可以发送1000条消息。另外broker也有接受消息最大的限制，message.max.bytes,(参考博主的broker配置文章)所以两边最好能够匹配。避免生产者发送消息被broker拒绝。

requests.timeout.ms：生产者发送数据时等待服务器返回响应的时间
```



## 简单Demo

**maven 依赖**

```
1.spring项目

<dependency>
   <groupId>org.springframework.kafka</groupId>
   <artifactId>spring-kafka</artifactId>
</dependency>

2.普通java项目

<dependency>
  <groupId>org.apache.kafka</groupId>
  <artifactId>kafka-clients</artifactId>
  <version>2.0.0</version>
  <scope>compile</scope>
</dependency>
<dependency>
  <groupId>org.apache.kafka</groupId>
  <artifactId>kafka-streams</artifactId>
  <version>2.0.0</version>
  <scope>compile</scope>
  <optional>true</optional>
</dependency>
```



**实例代码**

```
1.最简单使用

Properties props = new Properties();
//配置kafka的ip地址及端口
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
//配置接收模式为需要所有broken确认
props.put(ProducerConfig.ACKS_CONFIG, "all");
//设置消息发送失败重试次数
props.put(ProducerConfig.RETRIES_CONFIG, 3);
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
props.put(ProducerConfig.LINGER_MS_CONFIG, 1);
props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
//设置消息发送是键采用的序列化模式
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
//设置消息发送是值采用的序列化模式
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
String topic = "my-topic";
Producer<String, String> producer = new KafkaProducer<>(props);
producer.send(new ProducerRecord<String, String>(topic, "hello", "yinchong"));
producer.close();

2.发送指定分区

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;

import java.util.List;
import java.util.Map;
import java.util.Random;

public class MyPartition implements Partitioner {

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitionInfos = cluster.availablePartitionsForTopic(topic);
        int number = partitionInfos.size();
        int randomPartition = new Random().nextInt(number);
        return randomPartition;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> map) {

    }
}

在上面发送添加下面参数：
props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,"com.example.demo.kafka.MyPartition");

```

